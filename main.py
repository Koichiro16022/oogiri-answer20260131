import re
import os
import random
import asyncio
import numpy as np
import streamlit as st
import google.generativeai as genai
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip, AudioFileClip, CompositeAudioClip, concatenate_audioclips, AudioClip
from gtts import gTTS
import edge_tts

# --- 1. åŸºæœ¬è¨­å®š ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("APIã‚­ãƒ¼ãŒSecretsã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

CHOSEN_MODEL = 'models/gemini-2.0-flash'
FONT_PATH = "NotoSansJP-Bold.ttf"
BASE_VIDEO = "template.mp4"
SOUND1 = "sound1.mp3"
SOUND2 = "sound2.mp3"

st.set_page_config(page_title="å¤§å–œåˆ©ã‚¢ãƒ³ã‚µãƒ¼", layout="wide")

st.markdown("""
    <style>
    .main { background-color: #001220; color: #E5E5E5; }
    .stButton>button { width: 100%; border-radius: 5px; font-weight: bold; }
    div.stButton > button:first-child { background: linear-gradient(135deg, #FFD700 0%, #E5E5E5 100%); color: #001220; }
    .stVideo { max-width: 100%; margin: auto; }
    .pronounce-box { font-size: 0.8rem; color: #FFD700; margin-top: -10px; margin-bottom: 10px; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. çŠ¶æ…‹ç®¡ç† ---
if 'kw' not in st.session_state: st.session_state.kw = "SNS"
if 'odais' not in st.session_state: st.session_state.odais = []
if 'selected_odai' not in st.session_state: st.session_state.selected_odai = ""
if 'ans_list' not in st.session_state: st.session_state.ans_list = []
if 'pronounce_list' not in st.session_state: st.session_state.pronounce_list = []

# åˆæœŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆ1/31å½“æ™‚ã®å‚‘ä½œé¸ï¼‰
if 'golden_examples' not in st.session_state:
    st.session_state.golden_examples = [
        {"odai": "ç›®ã«å…¥ã‚Œã¦ã‚‚ç—›ããªã„å­«ã«ãŠã˜ã„ã¡ã‚ƒã‚“ãŒãƒ–ãƒã‚®ãƒ¬ã€‚ã„ã£ãŸã„ä½•ãŒã‚ã£ãŸï¼Ÿ", "ans": "ãŠã˜ã„ã¡ã‚ƒã‚“ã®å…¥ã‚Œæ­¯ã‚’ãƒ¡ãƒ«ã‚«ãƒªã§ã€ãƒ“ãƒ³ãƒ†ãƒ¼ã‚¸é›‘è²¨ã€ã¨ã—ã¦å‡ºå“ã—ã¦ã„ãŸ"},
        {"odai": "ã“ã®ç•ªçµ„çµ¶å¯¾ãƒ‰ãƒƒã‚­ãƒªã ã‚ï¼ãªãœæ°—ä»˜ã„ãŸï¼Ÿ", "ans": "é€šè¡Œäºº10äººå…¨å“¡ãŒã‚ˆãè¦‹ãŸã‚‰ã‚¨ã‚­ã‚¹ãƒˆãƒ©ã®ãƒã‚¤ãƒˆå‹Ÿé›†ã§è¦‹ã‹ã‘ãŸé¡”ã ã£ãŸ"},
        {"odai": "ãƒã‚²ã¦ã¦è‰¯ã‹ã£ãŸï½ãªãœãã†æ€ã£ãŸï¼Ÿ", "ans": "è·è³ªã®ãƒ—ãƒ­ã«ã€å›ã€éš ã—äº‹ãªã•ãã†ãªé ­ã—ã¦ã‚‹ã­ã€ã¨ã‚¹ãƒ«ãƒ¼ã•ã‚ŒãŸ"},
        {"odai": "ãƒã‚²ã¦ã¦è‰¯ã‹ã£ãŸï½ãªãœãã†æ€ã£ãŸï¼Ÿ", "ans": "ç¾å®¹å¸«ã•ã‚“ã«ãŠä»»ã›ã§ã¨è¨€ã£ãŸã‚‰3ç§’ã§ä¼šè¨ˆãŒçµ‚ã‚ã£ãŸ"},
        {"odai": "æ¯è¦ªãŒç§ã®å‹é”ã«å¤§æ¿€æ€’ã€‚ã„ã£ãŸã„ä½•ãŒã‚ã£ãŸï¼Ÿ", "ans": "å®¶æ—å†™çœŸã®ãŠæ¯ã•ã‚“ã®é¡”ã®éƒ¨åˆ†ã ã‘ã«åŸ·æ‹—ã«ã€ãƒ–ã‚µã‚¤ã‚¯ã«ãªã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ã‚’ã‹ã‘ã¦ä¿å­˜ã—ãŸ"},
        {"odai": "æ¯è¦ªãŒç§ã®å‹é”ã«å¤§æ¿€æ€’ã€‚ã„ã£ãŸã„ä½•ãŒã‚ã£ãŸï¼Ÿ", "ans": "ãŠæ¯ã•ã‚“ãŒå¤§åˆ‡ã«ã—ã¦ã„ã‚‹è¦³è‘‰æ¤ç‰©ã‚’å‹æ‰‹ã«ãƒ¡ãƒ«ã‚«ãƒªã§å£²ã‚ŒãŸã‚“ã§ã¨æ¢±åŒ…ã—å§‹ã‚ãŸ"},
        {"odai": "æ¯è¦ªãŒç§ã®å‹é”ã«å¤§æ¿€æ€’ã€‚ã„ã£ãŸã„ä½•ãŒã‚ã£ãŸï¼Ÿ", "ans": "ãŠã°ã•ã‚“ãã®æœã‚«ãƒ¼ãƒ†ãƒ³ã¨åŒã˜æŸ„ã§ã™ã­ï¼ã¨æ˜ã‚‹ãæŒ‡æ‘˜ã—ãŸ"},
        {"odai": "æ¯è¦ªãŒç§ã®å‹é”ã«å¤§æ¿€æ€’ã€‚ã„ã£ãŸã„ä½•ãŒã‚ã£ãŸï¼Ÿ", "ans": "ãŠæ¯ã•ã‚“ã®å¯é¡”ã‚’å‹æ‰‹ã«æ’®å½±ã—ã¦#åŒ–ã‘ç‰© #æ‹¡æ•£å¸Œæœ›ã§ã‚¢ãƒƒãƒ—ã—ã‚ˆã†ã¨ã—ã¦ã„ãŸ"},
        {"odai": "ã¨ã‚ã‚‹å¤§å­¦ã®ã—ããŸã‚ŠãŒ1å¹´ç”Ÿã¯å…¨å“¡æ¿€è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ä¸€æ°—é£Ÿã„ã ãŒã€ã‚ã‚‹ç”Ÿå¾’ã ã‘ã¯3å¹´ç”Ÿã«ãªã£ã¦ã‚‚ã‚„ã‚‰ã•ã‚Œã¦ã„ãŸã€‚ä¸€ä½“ãªãœï¼Ÿ", "ans": "ã‚ã¾ã‚Šã«ã‚‚ç¾å‘³ã—ãã†ã«é£Ÿã¹ã‚‹ã®ã§åº—å´ãŒã€ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ãƒ“ãƒ‡ã‚ªã€ã‚’æ’®ã‚Šç¶šã‘ã¦ã„ã‚‹"},
        {"odai": "ã¨ã‚ã‚‹å¤§å­¦ã®ã—ããŸã‚ŠãŒ1å¹´ç”Ÿã¯å…¨å“¡æ¿€è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ä¸€æ°—é£Ÿã„ã ãŒã€ã‚ã‚‹ç”Ÿå¾’ã ã‘ã¯3å¹´ç”Ÿã«ãªã£ã¦ã‚‚ã‚„ã‚‰ã•ã‚Œã¦ã„ãŸã€‚ä¸€ä½“ãªãœï¼Ÿ", "ans": "æ¿€è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ã‚’å®Œé£Ÿã™ã‚‹ã¾ã§ãŒå…¥å­¦å¼ã¨ã„ã†ãƒ«ãƒ¼ãƒ«ã ãŒã¾ã ä¸€å£ã‚‚é£²ã¿è¾¼ã‚ã¦ã„ãªã„"},
        {"odai": "ã¨ã‚ã‚‹å¤§å­¦ã®ã—ããŸã‚ŠãŒ1å¹´ç”Ÿã¯å…¨å“¡æ¿€è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ä¸€æ°—é£Ÿã„ã ãŒã€ã‚ã‚‹ç”Ÿå¾’ã ã‘ã¯3å¹´ç”Ÿã«ãªã£ã¦ã‚‚ã‚„ã‚‰ã•ã‚Œã¦ã„ãŸã€‚ä¸€ä½“ãªãœï¼Ÿ", "ans": "ã€æ¿€è¾›ãƒ©ãƒ¼ãƒ¡ãƒ³ä¸€æ°—é£Ÿã„éƒ¨ã€ã¨ã„ã†ä¸–ç•Œã§ä¸€ç•ªä¸æ¯›ãªéƒ¨æ´»ã®éƒ¨é•·ã«ãªã£ãŸã‹ã‚‰"},
        {"odai": "å‹é”ã¨2äººã§å¤ç•‘ä»»ä¸‰éƒã‚’è¦³ã¦ã„ã¦äº‹ä»¶ã‚’è§£æ±ºã—ãŸå¾Œã€å‹é”ãŒå¿…ãšã™ã‚‹è¡Œå‹•ã¨ã¯ï¼Ÿ", "ans": "ä»Šå›ã®çŠ¯è¡Œæ‰‹å£ã‚’ChatGPTã«å…¥åŠ›ã—ã€ã€ã‚‚ã£ã¨ãƒãƒ¬ã«ãã„æ–¹æ³•ã€ã‚’3æ¡ˆå‡ºã•ã›ã‚‹"},
        {"odai": "å‹é”ã¨2äººã§å¤ç•‘ä»»ä¸‰éƒã‚’è¦³ã¦ã„ã¦äº‹ä»¶ã‚’è§£æ±ºã—ãŸå¾Œã€å‹é”ãŒå¿…ãšã™ã‚‹è¡Œå‹•ã¨ã¯ï¼Ÿ", "ans": "çœŸã£æš—ãªéƒ¨å±‹ã§ãŠã§ã“ã«äººå·®ã—æŒ‡ã‚’å½“ã¦ãŸã¾ã¾ãƒ«ãƒ³ãƒã®å¾Œã‚’ãšã£ã¨è¿½ã„ã‹ã‘ã‚‹"},
        {"odai": "å‹é”ã¨2äººã§å¤ç•‘ä»»ä¸‰éƒã‚’è¦³ã¦ã„ã¦äº‹ä»¶ã‚’è§£æ±ºã—ãŸå¾Œã€å‹é”ãŒå¿…ãšã™ã‚‹è¡Œå‹•ã¨ã¯ï¼Ÿ", "ans": "è­¦å¯Ÿã®é‘‘è­˜ä¸¦ã¿ã®æ‰‹éš›ã§éƒ¨å±‹ã«æ®‹ã£ãŸç§ã®æŒ‡ç´‹ã‚’ã™ã¹ã¦æ‹­ãå–ã‚Šå§‹ã‚ã‚‹"}
    ]

# --- 3. éŸ³å£°ãƒ»å‹•ç”»ãƒ­ã‚¸ãƒƒã‚¯ ---
async def save_edge_voice(text, filename, voice_name, rate="+15%"):
    communicate = edge_tts.Communicate(text, voice_name, rate=rate)
    await communicate.save(filename)

def make_silence(duration):
    return AudioClip(lambda t: [0, 0], duration=duration, fps=44100)

def build_controlled_audio(full_text, mode="gtts"):
    parts = re.split(r'(_+)', full_text)
    clips = []
    for i, part in enumerate(parts):
        if not part: continue
        if '_' in part:
            duration = len(part) * 0.1
            clips.append(make_silence(duration))
        else:
            tmp_filename = f"part_{mode}_{i}.mp3"
            if mode == "gtts":
                tts = gTTS(part, lang='ja')
                tts.save(tmp_filename)
            else:
                asyncio.run(save_edge_voice(part, tmp_filename, "ja-JP-KeitaNeural", rate="+15%"))
            clips.append(AudioFileClip(tmp_filename))
    if not clips: return None
    return concatenate_audioclips(clips)

def create_text_image(text, fontsize, color, pos=(960, 540)):
    img = Image.new("RGBA", (1920, 1080), (255, 255, 255, 0))
    draw = ImageDraw.Draw(img)
    try: font = ImageFont.truetype(FONT_PATH, fontsize)
    except: return None
    
    # â˜…ä¿®æ­£: éŸ³å£°åˆ¶å¾¡ç”¨ã®_ã‚’å­—å¹•ã«ã¯è¡¨ç¤ºã—ãªã„ã€‚å…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã®ã¿ã‚’æ”¹è¡Œã«å¤‰æ›ã€‚
    clean_display = text.replace("_", "")
    display_text = clean_display.replace("ã€€", "\n").replace(" ", "\n")
    lines = display_text.split("\n")
    
    line_spacing = 15
    line_heights = [draw.textbbox((0, 0), line, font=font)[3] - draw.textbbox((0, 0), line, font=font)[1] for line in lines]
    total_height = sum(line_heights) + (len(lines) - 1) * line_spacing
    current_y = pos[1] - total_height // 2
    for i, line in enumerate(lines):
        bbox = draw.textbbox((0, 0), line, font=font)
        line_w = bbox[2] - bbox[0]
        draw.text((pos[0] - line_w // 2, current_y), line, font=font, fill=color)
        current_y += line_heights[i] + line_spacing
    return img

def create_geki_video(odai, answer_display, answer_audio):
    for f in [BASE_VIDEO, SOUND1, SOUND2]:
        if not os.path.exists(f): return None
    try:
        video = VideoFileClip(BASE_VIDEO).without_audio()
        clean_display = re.sub(r'^[0-9ï¼-ï¼™\.\sã€ã€‚ãƒ»ï¼Š\*]+', '', answer_display).strip()
        clean_audio = re.sub(r'^[0-9ï¼-ï¼™\.\sã€ã€‚ãƒ»ï¼Š\*]+', '', answer_audio).strip()
        
        # ç”»åƒç”Ÿæˆ
        i1 = create_text_image(odai, 100, "black", pos=(960, 530)) 
        i2 = create_text_image(odai, 55, "black", pos=(880, 300))
        i3 = create_text_image(clean_display, 120, "black", pos=(960, 500))
        
        c1 = ImageClip(np.array(i1)).set_start(2.0).set_end(8.0).set_duration(6.0)
        c2 = ImageClip(np.array(i2)).set_start(8.0).set_end(10.0).set_duration(2.0)
        c3 = ImageClip(np.array(i3)).set_start(10.0).set_end(16.0).set_duration(6.0)
        
        # éŸ³å£°ç”Ÿæˆ
        voice_odai_clip = build_controlled_audio(odai, mode="gtts")
        voice_ans_clip = build_controlled_audio(clean_audio, mode="edge")
        
        audio_list = []
        if voice_odai_clip: audio_list.append(voice_odai_clip.set_start(2.5))
        if voice_ans_clip: audio_list.append(voice_ans_clip.set_start(10.5))
        s1_audio = AudioFileClip(SOUND1).set_start(0.8).volumex(0.2)
        s2_audio = AudioFileClip(SOUND2).set_start(9.0).volumex(0.3)
        audio_list.extend([s1_audio, s2_audio])
        
        # æ˜ åƒãƒ»éŸ³å£°åˆæˆ
        video_composite = CompositeVideoClip([video, c1, c2, c3], size=(1920, 1080))
        final = video_composite.set_audio(CompositeAudioClip(audio_list))
        
        out = "geki.mp4"
        final.write_videofile(out, fps=24, codec="libx264", audio_codec="aac", remove_temp=True)
        video.close(); final.close()
        return out
    except Exception as e:
        st.error(f"åˆæˆå¤±æ•—: {e}"); return None

# --- 4. ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆé‡è¤‡é˜²æ­¢æ©Ÿèƒ½ã¤ãï¼‰ ---
with st.sidebar:
    st.header("ğŸ§  æ„Ÿæ€§åŒæœŸãƒ»è¿½åŠ å­¦ç¿’")
    with st.form("learning_form", clear_on_submit=True):
        new_odai = st.text_area("ãŠé¡Œã‚’è¿½åŠ ", height=100)
        new_ans = st.text_input("å›ç­”ã‚’è¿½åŠ ")
        if st.form_submit_button("æ„Ÿæ€§ã‚’è¦šãˆã•ã›ã‚‹"):
            if new_odai and new_ans:
                is_duplicate = any(ex["odai"] == new_odai and ex["ans"] == new_ans for ex in st.session_state.golden_examples)
                if not is_duplicate:
                    st.session_state.golden_examples.append({"odai": new_odai, "ans": new_ans})
                    st.success("ãŠé¡Œã¨å›ç­”ã‚’ç™»éŒ²ã—ã¾ã—ãŸã€‚")
                else:
                    st.warning("ãã®å†…å®¹ã¯æ—¢ã«ç™»éŒ²æ¸ˆã¿ã§ã™ã€‚")
    st.write(f"### å­¦ç¿’æ¸ˆã¿ãƒªã‚¹ãƒˆ ({len(st.session_state.golden_examples)}ä»¶)")
    for i, ex in enumerate(reversed(st.session_state.golden_examples)):
        idx = len(st.session_state.golden_examples) - i
        with st.expander(f"å‚‘ä½œ {idx}"):
            st.write(f"**ãŠé¡Œ**: {ex['odai']}")
            st.write(f"**å›ç­”**: {ex['ans']}")

# --- 5. ãƒ¡ã‚¤ãƒ³UI ---
st.title("å¤§å–œåˆ©ã‚¢ãƒ³ã‚µãƒ¼")
kw_col, clr_col, rnd_col = st.columns([5, 1, 1])
st.session_state.kw = kw_col.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value=st.session_state.kw, label_visibility="collapsed")
if clr_col.button("æ¶ˆå»"): st.session_state.kw = ""; st.rerun()
if rnd_col.button("ãƒ©ãƒ³ãƒ€ãƒ "): st.session_state.kw = random.choice(["AI", "å­«", "ã‚µã‚¦ãƒŠ"]); st.rerun()

if st.button("ãŠé¡Œç”Ÿæˆ", use_container_width=True):
    m = genai.GenerativeModel(CHOSEN_MODEL)
    r = m.generate_content(f"ã€Œ{st.session_state.kw}ã€ãƒ†ãƒ¼ãƒã®å¤§å–œåˆ©ãŠé¡Œã‚’3ã¤ã€‚å›ç­”ã®ã¿3è¡Œã§ã€‚")
    st.session_state.odais = [l.strip() for l in r.text.split('\n') if l.strip()][:3]
    st.session_state.selected_odai = ""; st.rerun()

if st.session_state.odais:
    for i, o in enumerate(st.session_state.odais):
        if st.button(o, key=f"o_{i}"): st.session_state.selected_odai = o; st.rerun()

if st.session_state.selected_odai:
    st.write("---")
    st.session_state.selected_odai = st.text_input("ãŠé¡Œç¢ºå®š", value=st.session_state.selected_odai)
    style = st.selectbox("ãƒ¦ãƒ¼ãƒ¢ã‚¢", ["é€šå¸¸", "çŸ¥çš„", "ã‚·ãƒ¥ãƒ¼ãƒ«", "ãƒ–ãƒ©ãƒƒã‚¯"])
    if st.button("å›ç­”20æ¡ˆç”Ÿæˆ", type="primary"):
        with st.spinner("æ€è€ƒä¸­..."):
            m = genai.GenerativeModel(CHOSEN_MODEL)
            ex = "\n".join([f"ãŠé¡Œï¼š{e['odai']}\nå›ç­”ï¼š{e['ans']}" for e in st.session_state.golden_examples])
            p = f"ä¼èª¬ã®å¤§å–œåˆ©å›ç­”è€…ã¨ã—ã¦ã€ãŠé¡Œã€‘:{st.session_state.selected_odai}ã«ç­”ãˆã‚ˆã€‚æ‰‹æœ¬:{ex}\nãƒ«ãƒ¼ãƒ«:å›ç­”ã®ã¿20å€‹ã€ç•ªå·ã‚’æŒ¯ã‚Š1è¡Œ1æ¡ˆã§ã€‚ã‚«ãƒƒã‚³èª¬æ˜ç¦æ­¢ã€‚"
            r = m.generate_content(p)
            ans_raw = [l.strip() for l in r.text.split('\n') if l.strip()][:20]
            st.session_state.ans_list = ans_raw
            st.session_state.pronounce_list = ans_raw[:]
            st.rerun()

if st.session_state.ans_list:
    list_len = min(len(st.session_state.ans_list), len(st.session_state.pronounce_list))
    st.write("### å›ç­”ä¸€è¦§ï¼ˆä¸‹ã®é»„è‰²ã„æ¬„ã§èª­ã¿æ–¹ã‚’ä¿®æ­£ã§ãã¾ã™ï¼‰")
    for i in range(list_len):
        col_t, col_g = st.columns([9, 1])
        st.session_state.ans_list[i] = col_t.text_input(f"å­—å¹•æ¡ˆ {i+1}", value=st.session_state.ans_list[i], key=f"disp_{i}")
        st.session_state.pronounce_list[i] = st.text_input(f"éŸ³å£°èª­ã¿ä¿®æ­£ {i+1}", value=st.session_state.pronounce_list[i], key=f"pron_{i}", label_visibility="collapsed")
        st.markdown(f'<p class="pronounce-box">â†‘ èª­ã¿ä¿®æ­£ï¼ˆä¾‹ï¼šãªã‚“ã€ã„ã„ã€_ã§é–“ã‚’é–‹ã‘ã‚‹ ç­‰ï¼‰</p>', unsafe_allow_html=True)
        
        if col_g.button("ç”Ÿæˆ", key=f"b_{i}"):
            with st.spinner("å‹•ç”»ç”Ÿæˆä¸­..."):
                path = create_geki_video(st.session_state.selected_odai, st.session_state.ans_list[i], st.session_state.pronounce_list[i])
                if path:
                    st.video(path)
                    with open(path, "rb") as f:
                        st.download_button("ä¿å­˜", f, file_name=f"geki_{i}.mp4", key=f"dl_{i}")

st.write("---")
st.caption("ã€Œç§ãŒ100%åˆ¶å¾¡ã—ã¦ã„ã¾ã™ã€")
